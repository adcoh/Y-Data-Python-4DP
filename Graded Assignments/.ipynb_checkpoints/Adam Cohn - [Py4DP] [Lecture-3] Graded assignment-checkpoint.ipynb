{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "This assignment is partially autograded. Problems 2 and 3 are graded manually according to the following rules:\n",
    "\n",
    "- **1 point**: attempt was made, but solution is not correct,\n",
    "- **2 points**: solution is generally correct, but is not efficient/has unreasonably low performance,\n",
    "- **3 points**: solution is correct, is efficient/has reasonably high performance.\n",
    "\n",
    "Problem 1 is auto-graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T22:00:31.331179Z",
     "start_time": "2019-11-13T22:00:30.492519Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T22:00:32.020415Z",
     "start_time": "2019-11-13T22:00:32.015416Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T22:00:34.357252Z",
     "start_time": "2019-11-13T22:00:32.305471Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T22:11:54.201123Z",
     "start_time": "2019-11-13T22:11:54.196430Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Gleb Ivashkevich\"\n",
    "ASSIGNMENT = 3\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate gradient (1 point).\n",
    "\n",
    "For 2-dimensional tensor `tr`, calculate a gradient of $\\sum\\log tr_{ij}$. Note, that you're provided with dimensions and interval:\n",
    "\n",
    "- `dims` is a tuple, so that `tr.size()` equals `dims`,\n",
    "- `lims` is an interval, so that `tr` elements are integeres, uniformly sampled from `[lims[0], lims[1])` interval (note, that lims[1] is **not** included).\n",
    "\n",
    "Result must be a tensor of the same shape as `tr`, containing gradients of the following function:\n",
    "\n",
    "$$\\sum_{ij}\\log tr_{ij}.$$\n",
    "\n",
    "Result **will be tested against multiple random combinations of input tensor dimensions ($10 \\leq n < 100 $) and sampling interval (`lims[0]=1`, `10 <= lims[1] < 100`)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grad(dims, lims):\n",
    "    \"\"\"Generate gradient of `log(x)`.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, generate_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find a minimum (2 points, manually graded).\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given the $a,b,c$, find $x$, which minimizes $f'(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:15:11.348224Z",
     "start_time": "2019-11-13T23:15:11.334569Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:25:50.106449Z",
     "start_time": "2019-11-13T23:25:50.095086Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LR = 1e-1\n",
    "STARTING_VAL = 51. # Consider choosing different starting values for x to speed-up the optimization\n",
    "\n",
    "# Initialize x, a, b, c\n",
    "x = None\n",
    "a, b, c = generate_coeffs()\n",
    "\n",
    "# Collect f(x) values during training for visuzalition later on\n",
    "f_vals = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # Your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:26:15.085855Z",
     "start_time": "2019-11-13T23:26:15.078760Z"
    }
   },
   "outputs": [],
   "source": [
    "if f_vals:\n",
    "    grid = np.linspace(-5, 5, 100)\n",
    "    plt.plot(grid, np.square(grid) * a.item() + grid * b.item() + c.item())\n",
    "    plt.hlines(f_vals[-1], -5, 5, \"firebrick\", \"--\", linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "GRADE = 0\n",
    "\n",
    "if TEST:\n",
    "    total_grade += GRADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simple neural network model (3 points, manually graded).\n",
    "\n",
    "Construct non-linear model for binary classification. Use logistic regressions example from class as a blueprint. Experiment with different number of intermediate layers and their sizes to achieve good performance.\n",
    "\n",
    "For a reference, imagine a neural network with a single hidden layer with $N$ neurons. Then, input $X$ is first transformed as:\n",
    "\n",
    "$$\n",
    "X^{hidden}_{ik} = \\sigma(X_{ij}W^{hidden}_{jk} + b^{hidden}_k),\n",
    "$$\n",
    "$$\n",
    "\\hat y_{i} = \\sigma(X^{hidden}_{ij}W_{j} + b).\n",
    "$$\n",
    "\n",
    "After this, $X^{hidden}_{ik}$ can be considered as an input to the same logistic regression model we had in class. The bonus is that we performed non-linear transformation of pur original coordinates and can now catch non-linear decision boundary (as is the case for our mock data).\n",
    "\n",
    "Note also, that $X$ has shape $(N, 2)$ (where $N$ is number of training examples), $W^{hidden}_{jk}$ has shape of $(2, N^{hidden})$ and $b^{hidden}_k$ has shape $(N^{hidden})$. At the same time, $W$ has shape $(N^{hidden},)$ and $b$ is a scalar (the same way it was for logistic regression). This model can be considered as a logistic regression on transformed coordinates, but we learn the transformation itself.\n",
    "\n",
    "There may be multiple hidden layers, but start from a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:45:05.939698Z",
     "start_time": "2019-11-13T23:45:05.933382Z"
    }
   },
   "outputs": [],
   "source": [
    "N_LAYERS = 1\n",
    "N_HIDDEN = (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:30:28.611111Z",
     "start_time": "2019-11-13T23:30:28.601529Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = datasets.make_moons(1000, noise=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:50:17.454916Z",
     "start_time": "2019-11-12T15:50:17.448528Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(X, dtype=torch.float)\n",
    "yt = torch.tensor(np.expand_dims(y, axis=-1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "\n",
    "for i in range(N_LAYERS):\n",
    "    # Initialize w and b for layer i with number of \"neurons\" of N_HIDDEN[i]\n",
    "    w = None # <- your code goes here\n",
    "    b = None # <- your code goes here\n",
    "    weights.append(w)\n",
    "    biases.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:54:14.621402Z",
     "start_time": "2019-11-12T15:54:14.615696Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "\n",
    "    return 1/(1 + (-a).exp())\n",
    "\n",
    "def output(X, weights, biases):\n",
    "    \"\"\"Calculate neural network output.\"\"\"\n",
    "    pass # <- your code goes here\n",
    "\n",
    "def logloss(y, y_pred):\n",
    "    return -(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:17:44.127854Z",
     "start_time": "2019-11-12T17:17:42.941153Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "LR = 1e-1\n",
    "DELTA = 0.00001\n",
    "loss_history = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    y_pred = output(Xt, weights, biases)\n",
    "    loss = logloss(yt, y_pred)\n",
    "    loss.backward()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # update all the weights and biases\n",
    "        # your code goes here\n",
    "        pass\n",
    "\n",
    "    # wipe out all gradients\n",
    "    # your code goes here\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Epoch {i}: loss = {loss_history[-1]}\")\n",
    "    \n",
    "    try:\n",
    "        if loss_history[-2] - loss_history[-1] < DELTA:\n",
    "            break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:18:22.877239Z",
     "start_time": "2019-11-12T17:18:21.271118Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred.detach().numpy().flatten(), alpha=0.6, edgecolor='k',\n",
    "            cmap=plt.cm.coolwarm, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x_0$', fontsize=14)\n",
    "plt.ylabel('$x_1$', fontsize=14)\n",
    "plt.title(\"Predicted targets\", fontsize=12)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.6, edgecolor='k',\n",
    "            cmap=plt.cm.coolwarm, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('$x_0$', fontsize=14)\n",
    "plt.ylabel('$x_1$', fontsize=14)\n",
    "plt.title(\"Actual targets\", fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:48:26.352733Z",
     "start_time": "2019-11-13T23:48:26.208103Z"
    }
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "GRADE = 0\n",
    "\n",
    "if TEST:\n",
    "    total_grade += GRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T23:48:26.479012Z",
     "start_time": "2019-11-13T23:48:26.459417Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {int(100 * total_grade / MAX_POINTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
